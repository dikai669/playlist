import requests
import re

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ URL –±–µ–∑ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
def fetch_url(url):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ URL –±–µ–∑ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è."""
    response = requests.get(url.strip(), headers={"Cache-Control": "no-cache"})
    if response.status_code != 200:
        raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–ª–µ–π–ª–∏—Å—Ç —Å URL: {url}. –°—Ç–∞—Ç—É—Å: {response.status_code}")
    
    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –¥–µ–∫–æ–¥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ UTF-8
    try:
        content = response.content.decode("utf-8")
    except UnicodeDecodeError:
        # –ï—Å–ª–∏ –Ω–µ UTF-8, –ø—Ä–æ–±—É–µ–º MacRoman –∏–ª–∏ –¥—Ä—É–≥—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É
        content = response.content.decode("MacRoman", errors="replace")
    
    return content.splitlines()

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ M3U –ø–ª–µ–π–ª–∏—Å—Ç–∞
def parse_m3u(url):
    """–ü–∞—Ä—Å–∏—Ç M3U —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –≥—Ä—É–ø–ø."""
    lines = fetch_url(url)
    groups = {}
    current_group = None
    group_content = []

    for line in lines:
        line = line.strip()
        if line.startswith("#EXTINF"):
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã –∏–∑ —Ç–µ–≥–∞ EXTGRP
            match = re.search(r'group-title="([^"]+)"', line)
            if match:
                group_name = match.group(1).strip()
                if group_name != current_group:
                    if current_group and group_content:
                        groups[current_group] = group_content
                    current_group = group_name
                    group_content = []
            group_content.append(line)
        elif line.startswith("#EXTVLCOPT") or line.startswith("http"):
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å EXTVLCOPT –∏ —Å—Å—ã–ª–∫–∏
            group_content.append(line)

    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –≥—Ä—É–ø–ø—É
    if current_group and group_content:
        groups[current_group] = group_content

    return groups


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Ç—Ä–æ–∫ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
def extract_metadata(url):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä–æ–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ü–µ–ª–µ–≤–æ–≥–æ –ø–ª–µ–π–ª–∏—Å—Ç–∞."""
    lines = fetch_url(url)
    metadata_lines = []

    for line in lines:
        if line.startswith("#EXTM3U") or line.startswith("#---"):
            metadata_lines.append(line)  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏

    return metadata_lines


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–ª–µ–π–ª–∏—Å—Ç–∞
def update_playlist(source_urls, target_url, output_file, special_group=None, special_source=None):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Ü–µ–ª–µ–≤–æ–π –ø–ª–µ–π–ª–∏—Å—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–¥–Ω–æ–≥–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤."""
    print("–ó–∞–≥—Ä—É–∑–∫–∞ —Ü–µ–ª–µ–≤–æ–≥–æ –ø–ª–µ–π–ª–∏—Å—Ç–∞...")
    target_groups = parse_m3u(target_url)
    print(f"–ì—Ä—É–ø–ø—ã –≤ —Ü–µ–ª–µ–≤–æ–º –ø–ª–µ–π–ª–∏—Å—Ç–µ: {list(target_groups.keys())[:20]} (–≤—ã–≤–µ–¥–µ–Ω–æ –¥–æ 20)")

    # –û–±–Ω–æ–≤–ª—è–µ–º –≥—Ä—É–ø–ø—ã –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –∏—Å—Ö–æ–¥–Ω–∏–∫–∞
    source_groups = parse_m3u(source_urls[0])
    print(f"–ì—Ä—É–ø–ø—ã –≤ –ø–µ—Ä–≤–æ–º –∏—Å—Ö–æ–¥–Ω–∏–∫–µ: {list(source_groups.keys())[:20]} (–≤—ã–≤–µ–¥–µ–Ω–æ –¥–æ 20)")

    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    updated_groups = set()
    for group in target_groups:
        if group in source_groups:
            print(f"[–û–ë–ù–û–í–õ–ï–ù–ò–ï] –ì—Ä—É–ø–ø–∞ '{group}' —É–¥–∞–ª–µ–Ω–∞ –∏–∑ —Ü–µ–ª–µ–≤–æ–≥–æ –ø–ª–µ–π–ª–∏—Å—Ç–∞ –∏ –∑–∞–º–µ–Ω–µ–Ω–∞ –Ω–∞ –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –∏—Å—Ö–æ–¥–Ω–∏–∫–∞.")
            target_groups[group] = source_groups[group]
            updated_groups.add(group)

    print(f"–û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –≥—Ä—É–ø–ø—ã: {sorted(updated_groups)}")

    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é –≥—Ä—É–ø–ø—É –∏–∑ –≤—Ç–æ—Ä–æ–≥–æ –∏—Å—Ö–æ–¥–Ω–∏–∫–∞
    if special_group and special_source:
        special_source_groups = parse_m3u(special_source)
        if special_group in special_source_groups and special_group in target_groups:
            print(f"[–û–ë–ù–û–í–õ–ï–ù–ò–ï] –ì—Ä—É–ø–ø–∞ '{special_group}' —É–¥–∞–ª–µ–Ω–∞ –∏–∑ —Ü–µ–ª–µ–≤–æ–≥–æ –ø–ª–µ–π–ª–∏—Å—Ç–∞ –∏ –∑–∞–º–µ–Ω–µ–Ω–∞ –Ω–∞ –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤—Ç–æ—Ä–æ–≥–æ –∏—Å—Ö–æ–¥–Ω–∏–∫–∞.")
            target_groups[special_group] = special_source_groups[special_group]

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    metadata_lines = extract_metadata(target_url)

    # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π –ø–ª–µ–π–ª–∏—Å—Ç
    with open(output_file, "w", encoding="utf-8") as f:
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        for metadata_line in metadata_lines:
            f.write(f"{metadata_line}\n")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≥—Ä—É–ø–ø—ã –∏ –∫–∞–Ω–∞–ª—ã
        for group, channels in target_groups.items():
            for channel in channels:
                f.write(f"{channel}\n")
    
    print(f"–ü–ª–µ–π–ª–∏—Å—Ç —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª—ë–Ω –∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {output_file}!")


# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
if __name__ == "__main__":
    # URL –∏—Å—Ö–æ–¥–Ω—ã—Ö –ø–ª–µ–π–ª–∏—Å—Ç–æ–≤
    source_url_1 = "https://raw.githubusercontent.com/IPTVSHARED/iptv/refs/heads/main/IPTV_SHARED.m3u"
    source_url_2 = "https://raw.githubusercontent.com/Dimonovich/TV/Dimonovich/FREE/TV"
    target_url = "https://cdn.jsdelivr.net/gh/dikai669/playlist@main/mpll.m3u"
    output_file = "mpll.m3u"

    # –ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–∑ –≤—Ç–æ—Ä–æ–≥–æ –∏—Å—Ö–æ–¥–Ω–∏–∫–∞
    special_group = "Lime (VPN üá∑üá∫)"

    # –û–±–Ω–æ–≤–ª—è–µ–º –ø–ª–µ–π–ª–∏—Å—Ç
    try:
        update_playlist(
            source_urls=[source_url_1, source_url_2],
            target_url=target_url,
            output_file=output_file,
            special_group=special_group,
            special_source=source_url_2
        )
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {e}")
